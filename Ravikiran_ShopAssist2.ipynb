{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e65fc70",
   "metadata": {
    "id": "2e65fc70"
   },
   "source": [
    "# ShopAssistAI 2.0 with Function Calling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pVP7Nxn1BaY_",
   "metadata": {
    "id": "pVP7Nxn1BaY_"
   },
   "source": [
    "## Part 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7TYMV7XA-ae",
   "metadata": {
    "id": "e7TYMV7XA-ae"
   },
   "source": [
    "\n",
    "#### Project Background\n",
    "With the rapid growth of e-commerce, online shopping has become the preferred choice for many. However, the sheer volume of options and lack of tailored assistance often leave consumers overwhelmed. To address this challenge, we developed ShopAssist AIâ€”an intelligent chatbot that leverages large language models combined with rule-based functions to deliver accurate, personalized recommendations and streamline the shopping experience.\n",
    "\n",
    "#### Problem Statement\n",
    "Create a chatbot that processes a dataset containing detailed information about laptops, including product names, specifications, and descriptions. The chatbot must provide accurate and personalized laptop recommendations tailored to user requirements, ensuring a seamless and efficient shopping experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108f4bac",
   "metadata": {
    "id": "108f4bac"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jgmu_WDQBKP2",
   "metadata": {
    "id": "Jgmu_WDQBKP2"
   },
   "source": [
    "#### Approach:\n",
    "\n",
    "1. **Conversation and Information Gathering**: The chatbot will utilize language models to understand and generate natural responses. Through a conversational flow, it will ask relevant questions to gather information about the user's requirements.\n",
    "2. **Information Extraction**: Once the essential information is collected, rule-based functions come into play, extracting top 3 laptops that best matches the user's needs.\n",
    "3. **Personalized Recommendation**: Leveraging this extracted information, the chatbot engages in further dialogue with the user, efficiently addressing their queries and aiding them in finding the perfect laptop solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ovfx8S28BSHX",
   "metadata": {
    "id": "ovfx8S28BSHX"
   },
   "source": [
    "## Part 2: System Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IzLsdZxNBQKN",
   "metadata": {
    "id": "IzLsdZxNBQKN"
   },
   "source": [
    "#### Dataset\n",
    "\n",
    "We have a dataset `laptop.csv` where  each row describes the features of a single laptop and also has a small description at the end. The chatbot that we build will leverage LLMs to parse this `Description` column and provide recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V_leOT9kB5Zu",
   "metadata": {
    "id": "V_leOT9kB5Zu"
   },
   "source": [
    "#### Workings of the Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q0KUiiWEB2OM",
   "metadata": {
    "id": "q0KUiiWEB2OM"
   },
   "source": [
    "The chatbot should ask a series of questions to\n",
    "- Determine the user's requirments. For simplicity, we have used 6 features to encapsulate the user's needs. The 6 features are as follows:\n",
    "    - GPU intensity\n",
    "    - Display quality\n",
    "    - Portability\n",
    "    - Multitasking\n",
    "    - Processing speed\n",
    "    - Budget\n",
    "\n",
    "- Confirm if the user's requirements have been correctly captured at the end.\n",
    "\n",
    "After that the chatbot lists down the top 3 products that are the most relevant, and engages in further conversation to help the user find the best one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RAVIF2nZBoY9",
   "metadata": {
    "id": "RAVIF2nZBoY9"
   },
   "source": [
    "##### Major functions behind the Chatbot\n",
    "\n",
    "Let's now look at a brief overview of the major functions that form the chatbot. We'll take a deep dive later\n",
    "\n",
    "\n",
    "\n",
    "- `initialize_conversation()`: This initializes the variable conversation with the system message.\n",
    "- `chat_completions_function_calling()`: This takes the ongoing conversation as the input, calls the relevant function from the tools available to it and then returns the response from the assistant.\n",
    "- `moderation_check()`: This checks if the user's or the assistant's message is inappropriate. If any of these is inappropriate, it ends the conversation.\n",
    "- `compare_laptops_with_user()`: This function compares the user's profile with the different laptops and come back with the top 3 recommendations.\n",
    "\n",
    "The existing architecture of ShopAssist 1.0 was modified to leverage the Function Calling API's capabilities for improved performance. Layers which can be removed were identified and existing layers were updated to handle the new approach.\n",
    "\n",
    "The layers that were removed as their purpose was fulfilled by function calling were:\n",
    "- `intent_confirmation_layer()`: This function takes the assistant's response and evaluates if the chatbot has captured the user's profile clearly. Specifically, this checks if the following properties for the user has been captured or not GPU intensity, Display quality, Portability, Multitasking, Processing speed, Budget\n",
    "- `dictionary_present()`: This function checks if the final understanding of user's profile is returned by the chatbot as a python dictionary or not. If there is a dictionary, it extracts the information as a Python dictionary.\n",
    "- `initialize_conv_reco()`: Initializes the recommendations conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gczn5CerMdXw",
   "metadata": {
    "id": "gczn5CerMdXw"
   },
   "source": [
    "`Stage 1`\n",
    "\n",
    "- Intent Clarity Layer\n",
    "\n",
    "`Stage 2`\n",
    "\n",
    "- Product Mapping Layer\n",
    "\n",
    "`Stage 3`\n",
    "\n",
    "- Product Recommendation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c623ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85c623ea",
    "outputId": "2a10e8ec-c441-4bfc-fc01-3ecf194b220f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.11/site-packages (1.55.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (2.5.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/lib/python3.11/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/homebrew/lib/python3.11/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.1 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "\n",
    "# Import the libraries\n",
    "import os, json, ast\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ca14c9-f2e7-4e8f-932d-b15fb0c65e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = open(\"OpenAI_API_Key.txt\", \"r\").read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KBpsVrWVL_L3",
   "metadata": {
    "id": "KBpsVrWVL_L3"
   },
   "source": [
    "## Part 3: Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EMGP6CGyIRV4",
   "metadata": {
    "id": "EMGP6CGyIRV4"
   },
   "source": [
    "### Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c33c213",
   "metadata": {
    "id": "0c33c213"
   },
   "outputs": [],
   "source": [
    "# function to initialize the conversation with the AI assistant\n",
    "# this would be the system message for the api call\n",
    "def initialize_conversation():\n",
    "\n",
    "    delimiter = \"####\"\n",
    "\n",
    "    system_message = f\"\"\"\n",
    "    You are an expert laptop recommendation system. You evaluate requests for laptops based on the following\n",
    "    parameters: GPU intensity, display quality, portability, multitasking, processing speed, and budget.\n",
    "    You need to ask relevant questions to the user in case these points needed are not satisfied\n",
    "    as per the input query.\n",
    "\n",
    "    Based on the input query given by the user, you will need to determine details for the following keys\n",
    "    only: ('gpu intensity', 'display quality', 'portability', 'multitasking', 'processing speed', 'budget').\n",
    "    The values taken in for all the keys as shown above other than budget need to be as per ('low', 'medium', 'high').\n",
    "    The assignment of these values should be based on the importance given by the user for each of the parameters\n",
    "    in consideration. The value for budget needs to be filled in with the actual value as given by the user.\n",
    "\n",
    "    Once you ask the relevant questions and get all the details from the user, your goal is to fetch details of the\n",
    "    top 3 laptops which match the specifications as given by the user by using function calling with\n",
    "    the compare_laptops_with_user function.\n",
    "\n",
    "    {delimiter}\n",
    "    Once you get the list of top 3 laptops you will need to neatly format it and show the recomendations to the\n",
    "    user in the following format:\n",
    "    1. <Laptop name>: <Basic laptop specs in brief>, <price of laptop>\n",
    "    2. <Laptop name>: <Basic laptop specs in brief>, <price of laptop>\n",
    "    3. <Laptop name>: <Basic laptop specs in brief>, <price of laptop>\n",
    "    {delimiter}\n",
    "\n",
    "    {delimiter}\n",
    "    Here are some instructions for the values assigned for the different keys.\n",
    "    If you do not follow this, you'll be heavily penalised.\n",
    "    - The values for all keys, except 'Budget', should strictly be either 'low', 'medium', or 'high' based on\n",
    "    the importance of the corresponding keys, as stated by user.\n",
    "    - The value for 'budget' should be a numerical value extracted from the user's response.\n",
    "    - 'budget' value needs to be greater than or equal to 25000 INR. If the user says less than that,\n",
    "    please mention that there are no laptops in that range and ask them to reconsider or direct them to a live cutomer service agent.\n",
    "    - Do not randomly assign values to any of the keys. The values need to be inferred from the user's response.\n",
    "    - Do not output the python dictionary to the user.\n",
    "    - Do not explicitly ask the user to input the values as low, medium or high. These values should be inferred by you from\n",
    "    the response given by the user for the questions being asked.\n",
    "    - Do not ask the user questions regarding more than 1 parameter. For instance, if the processing speed\n",
    "    requirement and multitasking requirement need to be decided, only ask a question regarding 1 of the parameters first. Refrain from\n",
    "    asking about both the parameters within one question.\n",
    "\n",
    "    {delimiter}\n",
    "\n",
    "    Follow the steps defined below to ensure that you get the required information from the user for all the\n",
    "    parameters:\n",
    "    {delimiter}\n",
    "    Step 1: Greet the user with a short message asking about the type of laptop they need or the purpose for\n",
    "    which they need it.\n",
    "    {delimiter}\n",
    "    Step 2: Based on the input given by the user, try to infer information for the keys as discussed above and\n",
    "    try to fill up the python dictionary only for the keys that are relevant.\n",
    "    {delimiter}\n",
    "    Step 3: In case the response given by the user doesn't satisfactorily cover all the keys of the python dictionary,\n",
    "    then based on the keys that are missed out, ask the user some basic questions to enable them to fill in information\n",
    "    that can help you fill the values for the remaining keys in the dictionary.\n",
    "    {delimiter}\n",
    "    Step 4: Repeat steps 2 and 3 until the python dictionary has all the necessary values filled up with a good level\n",
    "    of confidence. Remember to fill in the values only based on the user's input and don't make any assumptions. Remember to ask simple questions that cover only one parameter at a time.\n",
    "    Do not ask questions regarding more than one parameter at a time.\n",
    "    Confirm that the user has nothing else to add or clarify before moving to the next step.\n",
    "    {delimiter}\n",
    "    Follow the above chain of thoughts.\n",
    "\n",
    "    {delimiter}\n",
    "    A sample conversation with the user can be as follows:\n",
    "    User: \"I am a gamer. What type of laptop would be good for me?\",\n",
    "    Assistant: \"Since you are a gamer is it safe to say that you need a computer that can handle high quality\n",
    "    graphic content? Further, you would also be requiring a good quality display to complement your gaming needs.\",\n",
    "    User: \"Yes, that is correct. I generally play games like GTA 5, Cyberpunk 2077, Call of Duty. However, it is\n",
    "    not important for me to play these games on the highest settings possible. I would even enjoy them with a\n",
    "    medium to high graphics setting.\",\n",
    "    Assistant: \"Thank you for that information, that certainly helps me understand your needs better. Can you give\n",
    "    me some information on whether you would be having a need to carry your laptop around to multiple places or\n",
    "    would you use it primarily at one location?\",\n",
    "    User: \"I don't need to move my laptop around much. I would be mostly playing with the laptop at home only.\",\n",
    "    Assistant: \"Would you be doing a lot of tasks on your computer at the same time? Or is it mostly only going\n",
    "    to be for gaming? This would help me understand your multitasking needs as well as help me to understand the\n",
    "    kind of processor that you require\",\n",
    "    User: \"I generally wouldn't use my laptop for a lot of other purposes than gaming. There is hardly a chance\n",
    "    for me to do multiple things at the same time.\",\n",
    "    Assistant: \"That's great information. Finally, can you please give me some information on the budget that is\n",
    "    on your mind for the laptop?\",\n",
    "    User: \"Below 70000 INR\"\n",
    "\n",
    "    {delimiter}\n",
    "    Here is another sample conversation between the user and assistant:\n",
    "    User: \"Hi, I am an editor.\"\n",
    "    Assistant: \"Great! As an editor, you likely require a laptop that can handle demanding tasks. Hence, the\n",
    "    laptop should have high multitasking capability. You would also need a high end display for better visuals\n",
    "    and editing. May I know what kind of work do you primarily focus on? Are you more involved in video editing,\n",
    "    photo editing, or both? Understanding the specific type of editing work will help me tailor my recommendations\n",
    "    accordingly. Let me know if my understanding is correct until now.\"\n",
    "    User: \"I primarily work with After Effects.\"\n",
    "    Assistant: \"Thank you for providing that information. Working with After Effects involves working with\n",
    "    graphics, animations, and rendering, which will require high GPU. Do you work with high-resolution media\n",
    "    files, such as 4K videos or RAW photos? Understanding your file sizes will help determine the storage capacity\n",
    "    and processing power needed.\"\n",
    "    User: \"Yes, sometimes I work with 4K videos as well.\"\n",
    "    Assistant: \"Thank you for the information. Processing 4K vidoes will require a good processor and high GPU.\n",
    "    I think we have already determined earlier that you need a high GPU. To ensure I have a complete understanding\n",
    "    of your needs, I have one more question: Are you frequently on the go and require a laptop that is lightweight\n",
    "    and easy to carry, or do you primarily work from a stationary location?\"\n",
    "    User: \"Yes, sometimes I travel but do not carry my laptop.\"\n",
    "    Assistant:\"Could you kindly let me know your budget for the laptop? This will help me find options that fit\n",
    "    within your price range while meeting the specified requirements.\"\n",
    "    User: \"my max budget is 1.5lakh inr\"\n",
    "\n",
    "    {delimiter}\n",
    "    Here is another sample conversation between the user and assistant:\n",
    "    User: \"i am a basic business user\"\n",
    "    Assistant: \"As a basic business user, it's important to have a reliable laptop for your day-to-day tasks.\n",
    "    Based on your usage as a basic business user, do you prefer a laptop with a good quality display for\n",
    "    presentations?\"\n",
    "    User: \"yes\"\n",
    "    Assistant: \"Great! Do you prefer a laptop that is easy to carry around or do you primarily use it at a fixed\n",
    "    location?\"\n",
    "    User: \"i need it to be easy to carry around\"\n",
    "    Assistant: \"Thank you for specifying that. Do you often have multiple tasks running on your laptop\n",
    "    simultaneously or primarily focus on one task at a time?\"\n",
    "    User: \"i ususally have multiple tasks running\"\n",
    "    Assistant: \"Thank you for sharing that. Do you prefer a laptop with fast processing speed for quick\n",
    "    performance?\"\n",
    "    User: \"yes i need it to be very quick\"\n",
    "    Assistant: \"Appreciate that input. Finally, what is your budget range for the laptop you are looking to\n",
    "    purchase?\"\n",
    "    User: \"i would like if it is below 1 lakh\"\n",
    "    \"\"\"\n",
    "\n",
    "    conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4b43ae",
   "metadata": {
    "id": "ce4b43ae"
   },
   "outputs": [],
   "source": [
    "# performs moderation check on user and assisants inputs\n",
    "def moderation_check(user_input):\n",
    "\n",
    "    # Call the OpenAI API to perform moderation on the user's input.\n",
    "    moderation_response = openai.Moderation.create(input=user_input)\n",
    "\n",
    "    # Extract the moderation result from the API response.\n",
    "    flagged = moderation_response.results[0].flagged\n",
    "\n",
    "    # Check if the input was flagged by the moderation system. If flagged, return \"Flagged\" else return \"Not Flagged\"\n",
    "    return \"Flagged\" if flagged else \"Not Flagged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d587d8b3",
   "metadata": {
    "id": "d587d8b3"
   },
   "outputs": [],
   "source": [
    "# Define a Chat Completions API call\n",
    "# Define a Chat Completions API call\n",
    "def get_chat_completions(input, json_format=False):\n",
    "    \"\"\"\n",
    "    Generate chat completions using OpenAI.\n",
    "    \"\"\"\n",
    "\n",
    "    MODEL = \"gpt-3.5-turbo\"  # Ensure this model is available in your API version\n",
    "\n",
    "    try:\n",
    "        # Messages should be in the form of a list of dictionaries\n",
    "        messages = input\n",
    "\n",
    "        # Call the Chat Completions API\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        # Handle the response\n",
    "        if not json_format:\n",
    "            response_content = response.choices[0].message['content']\n",
    "        else:\n",
    "            response_content = json.loads(response.choices[0].message['content'])\n",
    "\n",
    "        return response_content\n",
    "\n",
    "    # Raise exception error\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with the call to LLM: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MuEV_3rQIIhS",
   "metadata": {
    "id": "MuEV_3rQIIhS"
   },
   "source": [
    "### Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f1db827",
   "metadata": {
    "id": "4f1db827"
   },
   "outputs": [],
   "source": [
    "# given a laptop description as an input extract the json parameters from it\n",
    "def product_map_layer(laptop_description):\n",
    "    delimiter = \"#####\"\n",
    "\n",
    "    lap_spec = {\n",
    "      \"gpu intensity\":\"(Type of the Graphics Processor)\",\n",
    "      \"display quality\":\"(Display Type, Screen Resolution, Display Size)\",\n",
    "      \"portability\":\"(Laptop Weight)\",\n",
    "      \"multitasking\":\"(RAM Size)\",\n",
    "      \"processing speed\":\"(CPU Type, Core, Clock Speed)\"\n",
    "    }\n",
    "\n",
    "    values = {'low','medium','high'}\n",
    "\n",
    "    prompt=f\"\"\"\n",
    "    You are an expert laptop specifications analyst. Your job is to extract the key features of laptops and classify them as per their requirements.\n",
    "    You will be given a paragraph of text as input which represents information\n",
    "    about a laptop. Your task is to extract information for the keys:\n",
    "    'GPU intensity','Display quality','Portability','Multitasking','Processing speed' based on the information\n",
    "    present in the paragraph of text.\n",
    "    {delimiter}\n",
    "    'gpu intensity' must be decided with these rules:\n",
    "    - low: Integrated graphics (e.g., Intel UHD, Intel Iris Plus, AMD Radeon integrated graphics)\n",
    "    - medium: Entry-level to mid-range dedicated graphics (e.g., NVIDIA GTX, AMD Radeon)\n",
    "    - high: High-end dedicated graphics (e.g., NVIDIA RTX, AMD Radeon Pro, NVIDIA Quadro)\n",
    "\n",
    "    'display quality' must be decided with these rules:\n",
    "    - low: Resolution below Full HD (e.g., 1366x768)\n",
    "    - medium: Full HD resolution (1920x1080) or higher\n",
    "    - high: High-resolution display (e.g., 4K, Retina, OLED) with excellent color accuracy and features like HDR support\n",
    "\n",
    "    'portability' must be decided with these rules:\n",
    "    - low: Weighs more than 2.5 kg\n",
    "    - medium: Weighs between 1.5 kg and 2.5 kg\n",
    "    - high: Weighs less than 1.5 kg\n",
    "\n",
    "    'multitasking' must be decided with these rules:\n",
    "    - low: 8GB to 12GB of RAM\n",
    "    - medium: 12GB to 16GB of RAM\n",
    "    - high: 32GB or more of RAM\n",
    "\n",
    "    'processing speed' must be decided with these rules:\n",
    "    - low: Processor clock speed below 2.3 GHz. Should be considered for entry-level processors like Intel Core i3, AMD Ryzen 3\n",
    "    - medium: Processor clock speed between 2.3 GHz and 2.8 GHz. Should be considered for Mid-range processors like Intel Core i5, AMD Ryzen 5\n",
    "    - high: Processor clock speed above 2.8 GHz. Should be considered for High-performance processors like Intel Core i7, AMD Ryzen 7 or higher\n",
    "    {delimiter}\n",
    "\n",
    "    {delimiter}\n",
    "    Here are some example outputs for a better understanding of the task:\n",
    "    input1: \"The Dell Inspiron is a versatile laptop that combines powerful performance and affordability. It features an Intel Core i5 processor clocked at 2.4 GHz, ensuring smooth multitasking and efficient computing. With 8GB of RAM and an SSD, it offers quick data access and ample storage capacity. The laptop sports a vibrant 15.6\" LCD display with a resolution of 1920x1080, delivering crisp visuals and immersive viewing experience. Weighing just 2.5 kg, it is highly portable, making it ideal for on-the-go usage. Additionally, it boasts an Intel UHD GPU for decent graphical performance and a backlit keyboard for enhanced typing convenience. With a one-year warranty and a battery life of up to 6 hours, the Dell Inspiron is a reliable companion for work or entertainment. All these features are packed at an affordable price of 35,000, making it an excellent choice for budget-conscious users.\"\n",
    "    output1: {{'gpu intensity': 'medium','display quality':'medium','portability':'medium','multitasking':'high','processing speed':'medium'}}\n",
    "\n",
    "    input2: \"The Lenovo ThinkPad X1 Carbon is a sleek and lightweight laptop designed for professionals on the go. It is equipped with an Intel Core i7 processor running at 2.6 GHz, providing strong processing capabilities for multitasking and productivity. With 16GB of RAM and an SSD, it offers fast and efficient performance along with ample storage capacity. The laptop features a 14\" IPS display with a resolution of 2560x1440, delivering sharp visuals and accurate colors. It comes with Intel UHD integrated graphics for decent graphical performance. Weighing just 1.13 kg, it is extremely lightweight and highly portable. The laptop features an IR camera for face unlock, providing convenient and secure login options. With a three-year warranty and an impressive battery life of up to 12 hours, the Lenovo ThinkPad X1 Carbon ensures reliability and long-lasting productivity. Priced at 130,000, it offers top-notch performance and portability for professionals.\"\n",
    "    output2: {{'gpu intensity': 'medium', 'display quality': 'high', 'portability': 'high', 'multitasking':'high', 'processing speed':'high'}}\n",
    "\n",
    "    input3: \"The Apple MacBook Pro is a high-end laptop that combines top-tier performance with a stunning display. It is equipped with an Intel Core i9 processor running at 2.9 GHz, providing exceptional processing power for demanding tasks and content creation. With 32GB of RAM and an SSD, it offers seamless multitasking and fast storage access for large projects. The laptop features a 16\" Retina display with a resolution of 3072x1920, delivering breathtaking visuals and precise color reproduction. It comes with an AMD Radeon graphics card, ensuring smooth graphics performance for professional applications. Weighing 2.02 kg, it is relatively lightweight for its size. The laptop features a True Tone display, adjusting the color temperature to match the ambient lighting for a more natural viewing experience. With a three-year warranty and a battery life of up to 10 hours, the Apple MacBook Pro offers reliability and endurance for professionals. Priced at 280,000, it caters to users who require uncompromising performance and a superior display for their demanding workloads.\"\n",
    "    output3: {{'gpu intensity': 'medium', 'display quality': 'high', 'portability': 'medium','multitasking': 'high', 'processing speed': 'high'}}\n",
    "    {delimiter}\n",
    "\n",
    "    ### Strictly don't keep any other text in the values of the JSON dictionary other than low or medium or high ###\n",
    "    \"\"\"\n",
    "\n",
    "    input = f\"\"\"Follow the prompt instructions step-by-step and output the dictionary in JSON format for the\n",
    "    following laptop {laptop_description}.\"\"\"\n",
    "\n",
    "    messages=[{\"role\": \"system\", \"content\":prompt},{\"role\": \"user\",\"content\":input}]\n",
    "    response = get_chat_completions(messages, json_format=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f158212",
   "metadata": {
    "id": "1f158212"
   },
   "outputs": [],
   "source": [
    "##Run this code once to extract product info in the form of a dictionary\n",
    "laptop_df= pd.read_csv('laptop_data.csv')\n",
    "\n",
    "## Create a new column \"laptop_feature\" that contains the dictionary of the product features\n",
    "laptop_df['laptop_feature'] = laptop_df['Description'].apply(lambda x: product_map_layer(x))\n",
    "\n",
    "# all the updated data is now being stored inside updated_laptop.csv\n",
    "laptop_df.to_csv(\"updated_laptop.csv\",index=False,header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fbda603",
   "metadata": {
    "id": "8fbda603"
   },
   "outputs": [],
   "source": [
    "def compare_laptops_with_user(user_req_string):\n",
    "    # read the updated laptop csv file with the added parameter json information\n",
    "    laptop_df = pd.read_csv('updated_laptop.csv')\n",
    "\n",
    "    # understand budget from the users requirement input dict\n",
    "    user_requirements = user_req_string\n",
    "    user_budget = int(user_requirements.get('budget', '0'))\n",
    "\n",
    "    # make a copy of the df and format the prices to a numeric value\n",
    "    filtered_laptops = laptop_df.copy()\n",
    "    filtered_laptops['Price'] = filtered_laptops['Price'].str.replace(',', '').astype(int)\n",
    "    filtered_laptops = filtered_laptops[filtered_laptops['Price'] <= user_budget].copy()\n",
    "\n",
    "    # # # Mapping string values 'low', 'medium', 'high' to numerical scores 0, 1, 2\n",
    "    mappings = {'low': 0, 'medium': 1, 'high': 2}\n",
    "\n",
    "    # # # Creating a new column 'Score' in the filtered DataFrame and initializing it to 0\n",
    "    filtered_laptops['Score'] = 0\n",
    "\n",
    "    # generate scores for each laptop\n",
    "    for index, row in filtered_laptops.iterrows():\n",
    "        # read the laptop_feature string which contains the json pertaining to the laptop and convert it to a dict\n",
    "        user_product_match_str = row['laptop_feature']\n",
    "        laptop_dict = ast.literal_eval(user_product_match_str)\n",
    "\n",
    "        # converting keys to lowercase\n",
    "        laptop_dict = {k.lower(): v for k,v in laptop_dict.items()}\n",
    "\n",
    "        score = 0\n",
    "\n",
    "        for key, user_value in user_requirements.items():\n",
    "            if key.lower() == 'budget':\n",
    "                continue\n",
    "            laptop_value = laptop_dict.get(key.lower(), None)\n",
    "            if laptop_value is not None:\n",
    "                laptop_mapping = mappings.get(laptop_value.lower(), -1)\n",
    "            else:\n",
    "                laptop_mapping = -1\n",
    "            user_mapping = mappings.get(user_value.lower(), -1)\n",
    "            if laptop_mapping >= user_mapping:\n",
    "                # if the laptop value is greater than or equal to the user value the score is incremented by 1\n",
    "                score += 1\n",
    "\n",
    "        filtered_laptops.loc[index, 'Score'] = score\n",
    "\n",
    "    # sort the laptops by score in descending order and return the top 5 products\n",
    "    top_laptops = filtered_laptops.drop('laptop_feature', axis=1)\n",
    "    top_laptops = top_laptops.sort_values('Score', ascending=False).head(3)\n",
    "\n",
    "    return top_laptops.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jMGJA_sBI8fm",
   "metadata": {
    "id": "jMGJA_sBI8fm"
   },
   "source": [
    "### Stage 3\n",
    "\n",
    "Using the Function Calling capability of OpenAI to trigger specific functions based on the input of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8beb3d47",
   "metadata": {
    "id": "8beb3d47"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_chat_completions_function_calling(input_messages):\n",
    "    model = 'gpt-3.5-turbo'\n",
    "\n",
    "    try:\n",
    "        # Create the initial response\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=input_messages,\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        # Check if the response involves a function call\n",
    "        function_call = response.choices[0].message.get(\"function_call\")\n",
    "        if function_call:\n",
    "            print(\"Function Call Detected:\", function_call)\n",
    "\n",
    "            # Map to the correct function\n",
    "            available_functions = {\n",
    "                \"compare_laptops_with_user\": compare_laptops_with_user,\n",
    "            }\n",
    "\n",
    "            function_name = function_call.get(\"name\")\n",
    "            function_args = json.loads(function_call.get(\"arguments\", \"{}\"))\n",
    "\n",
    "            # Call the function and get the response\n",
    "            if function_name in available_functions:\n",
    "                function_to_call = available_functions[function_name]\n",
    "                function_response = function_to_call(function_args)\n",
    "\n",
    "                # Prepare response for second API call\n",
    "                function_call_response_dict = {\n",
    "                    \"role\": \"function\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response\n",
    "                }\n",
    "\n",
    "                # Append function response to messages\n",
    "                input_messages.append(response.choices[0].message)\n",
    "                input_messages.append(function_call_response_dict)\n",
    "\n",
    "                # Make a second call to the model after function execution\n",
    "                second_response = openai.ChatCompletion.create(\n",
    "                    model=model,\n",
    "                    messages=input_messages,\n",
    "                    temperature=0\n",
    "                )\n",
    "\n",
    "                # Print the second response for debugging\n",
    "                print(\"Second Response:\", second_response)\n",
    "\n",
    "                # Return the final assistant message\n",
    "                return [{\"role\": \"assistant\", \"content\": second_response.choices[0].message['content']}]\n",
    "        \n",
    "        # If there is no function call, return the standard response\n",
    "        response_message = [{\"role\": \"assistant\", \"content\": response.choices[0].message['content']}]\n",
    "        return response_message\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZEf6eYZKJWii",
   "metadata": {
    "id": "ZEf6eYZKJWii"
   },
   "source": [
    "#### Dialogue Management System\n",
    "\n",
    "Bringing everything together, we create a `dialogue_mgmt_system()` function that contains the logic of how the different layers would interact with each other. This will be the function that we'll call to initiate the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d38d8dee",
   "metadata": {
    "id": "d38d8dee"
   },
   "outputs": [],
   "source": [
    "def dialogue_mgmt_system():\n",
    "    # initialize the conversation\n",
    "    conversation = initialize_conversation()\n",
    "\n",
    "    print(\"Assistant:\\nHow may I help you with your laptop selection?\\n\")\n",
    "\n",
    "    user_input = ''\n",
    "\n",
    "    while user_input.lower() != 'exit':\n",
    "        print(\"User: \")\n",
    "        user_input = input()\n",
    "\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"\\nAssistant:\\nThank you for using this service. Please do not hesitate to contact us if you need assistance. See you soon!\\n\")\n",
    "            break\n",
    "\n",
    "        conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "        response = get_chat_completions_function_calling(conversation)\n",
    "\n",
    "        if response is not None:\n",
    "            print(\"\\nAssistant:\\n\", response[0]['content'], '\\n')\n",
    "            conversation += response\n",
    "        else:\n",
    "            print(\"\\nAssistant:\\nI'm having trouble responding at the moment. Please try again.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "009319b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "009319b2",
    "outputId": "10309651-59f8-4613-ff3c-4d809c4a8dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:\n",
      "How may I help you with your laptop selection?\n",
      "\n",
      "User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Looking for gaming laptop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant:\n",
      " Great! Since you are looking for a gaming laptop, it's important to understand your requirements to recommend the best options. Can you please provide me with information on the level of GPU intensity you need for gaming? Additionally, do you prioritize display quality for an immersive gaming experience? \n",
      "\n",
      "User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " not sure about that\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant:\n",
      " No problem! Let's break it down further. When you play games, do you prefer them to run smoothly with good graphics quality, or are you okay with compromising a bit on the graphics for better performance? This will help me determine the GPU intensity level you might need. \n",
      "\n",
      "User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " i need the game to run smoothly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant:\n",
      " Got it! Smooth gameplay is important for you. How about the display quality? Do you prefer a high-quality display that enhances your gaming experience, or is it not a top priority for you? \n",
      "\n",
      "User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " high quality display is my priority too\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant:\n",
      " Great! Thanks for sharing that. Moving on, do you need the laptop to be highly portable, or is it okay if it's a bit heavier as long as it meets your gaming needs? \n",
      "\n",
      "User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " it should be fine with anything\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant:\n",
      " Understood. Next, do you usually multitask while gaming, or do you mainly focus on gaming without running multiple applications simultaneously? \n",
      "\n",
      "User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " i run multiple applications simultaneously\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant:\n",
      " Thank you for providing that information. Lastly, could you please specify your budget range for the gaming laptop you are looking to purchase? \n",
      "\n",
      "User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " anything is fine, money is not a constraint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant:\n",
      " Thank you for the information. Based on your responses, I have gathered the following details:\n",
      "- GPU Intensity: High\n",
      "- Display Quality: High\n",
      "- Portability: Medium\n",
      "- Multitasking: High\n",
      "- Processing Speed: Not specified\n",
      "- Budget: Not specified\n",
      "\n",
      "To provide you with the best recommendations, could you please specify your budget range for the gaming laptop? \n",
      "\n",
      "User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 1000$\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant:\n",
      " Thank you for providing the budget range. Based on the information you have shared, I will now compare laptops based on the criteria you have mentioned and get back to you with the top 3 recommendations shortly. \n",
      "\n",
      "User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " sure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant:\n",
      " I have found the top 3 gaming laptops that match your requirements:\n",
      "1. ASUS ROG Zephyrus G14: High GPU intensity, High display quality, Medium portability, High multitasking, Budget: $1000\n",
      "2. MSI GS66 Stealth: High GPU intensity, High display quality, Medium portability, High multitasking, Budget: $1000\n",
      "3. Razer Blade 15: High GPU intensity, High display quality, Medium portability, High multitasking, Budget: $1000\n",
      "\n",
      "These laptops should meet your gaming needs effectively. \n",
      "\n",
      "User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " thank you so much\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant:\n",
      " You're welcome! If you have any more questions or need further assistance in the future, feel free to ask. Enjoy your gaming with the new laptop! \n",
      "\n",
      "User: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant:\n",
      "Thank you for using this service. Please do not hesitate to contact us if you need assistance. See you soon!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function to start the dialogue management system\n",
    "dialogue_mgmt_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a4516-5505-44b9-9127-5e66fbd34057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
